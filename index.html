<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Hummus: RoboCup Team 2024 TU Delft">
  <meta name="keywords" content="Robocup 2024, Mobile Manipulation">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Hummus: Humans, Mobile Manipulators, and Us</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./css/bulma.min.css">
  <link rel="stylesheet" href="./css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./css/bulma-slider.min.css">
  <link rel="stylesheet" href="./css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./css/index.css">
  <link rel="icon" href="./images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./js/fontawesome.all.min.js"></script>
  <script src="./js/bulma-carousel.min.js"></script>
  <script src="./js/bulma-slider.min.js"></script>
  <script src="./js/index.js"></script>
</head>
<body>


<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://tud-hummus.github.io">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://github.com/tud-amr/fabrics">
            Fabrics
          </a>
          <a class="navbar-item" href="https://github.com/cpezzato/active_inference">
            Active Inference for Control
          </a>
          </a>
          <a class="navbar-item" href="https://github.com/cpezzato/decision_making">
            Active Inference for Decision Making
          </a>
        </div>
      </div>
    </div>

  </div>
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Hummus: Robocup 2024</h1>
          <h2 class="title is-4 publication-title">Hummus: Humans, Mobile
            Manipulators and Us</h2>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://github.com/fghzamani">Forough Zamani</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/LuziaKn">Luzia Knoedler</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/yj-Tang">Yujie Tang</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/cpezzato">Corrado Pezzato</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/saraybakker1">Saray Bakker</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://github.com/maxspahn">Max Spahn</a><sup>1</sup>,</span>
            </span>
            <span class="author-block">
              <a href="https://c-salmi.github.io/">Chadi Salmi</a><sup>1</sup>, and
            </span>
            <span class="author-block">
              <a href="https://www.tudelft.nl/staff/m.wisse/?cHash=41274e0e3907f9c9121d467c295c6c4d">Martijn Wisse</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Delft University of Technology</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/orgs/tud-hummus/repositories"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
                <a href="#qualification"
                  class="external-link button is-normal is-rounded is-dark">
                 <span>Qualification Materials</span>
                 </a>
                <a href="#philosophy"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Philosophy</span>
                  </a>
                <a href="#hardware"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Hardware</span>
                  </a>
                <a href="#methods"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Methods</span>
                  </a>
                <a href="#robothon"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Robothon2023</span>
                  </a>
                <a href="#publications"
                   class="external-link button is-normal is-rounded is-dark">
                  <span>Publications</span>
                  </a>
                <img src="assets/hummus_logo.jpeg" style='max-height: 250px' alt="">
                <img src="assets/group_image.jpeg" style='max-height: 200px' alt="">
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted controls loop playsinline height="100%">
        <source src="./assets/robocup_hummus.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Qualification Video</span> 
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!--Philosophy. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 id="philosophy" class="title is-3">Philosophy</h2>
        <div class="content has-text-justified">
          <p>
            Bringing robots to human-shared environments is a challenging task,
            and testing out capabilitise and robotic skills in home setup is the
            perfect stress test.
            Our solution to the RoboCup@Home challenge  2024 is built on three
            core principles:
            <ol>
              <li>Human taught trajectories</li>
              <li>Social Navigation</li>
              <li>Simplicity wins</li>
            </ol> 
          </p>
          <p>
          <i>Some description</i>
          </p>
        </div>
      </div>
    </div>
    <!--/ Philosopy. -->
</section>

<section id="hardware" class="section">
  <div class="container is-max-desktop">
    <!--Hardware. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Hardware - Custom Albert Robot</h2>
        <div class="content has-text-justified">
          <img src="assets/albert.jpg" alt="Albert Robot" class="robot-image">
          <p>
            Our robot Albert is a mobile manipulator consitsting of a differential drive Clearpath Boxer base 
            and a Franka Emika Panda arm equipped with a customised vacuum gripper. This combination provides a robust and agile robotic platform capable of 
            navigating various environments while offering sophisticated manipulation capabilities. 
            The Clearpath Boxer base serves as a reliable and mobile foundation, ensuring smooth and efficient movement, 
            while the Franka Emika Panda arm extends the robot's capabilities with its agile and dexterous manipulation features. 
            Together, these components create a synergistic fusion, enabling our robot to perform intricate tasks with precision and flexibility.
          </p>
        </div>
      </div>
    </div>
    <style>
      .robot-image {
        display: block;
        margin: auto;
        max-width: 100%;
        height: auto;
        max-height: 400px;
        margin-bottom: 20px;
      }
    </style>
    <!--/ Hardware. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!--Methods -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 id="methods" class="title is-3">Robothon 2023, Platonics</h2>
        <div class="content has-text-justified">
          <h3 class="title is-4">Navigation among Humans</h3>
          <p>
            To successfully integrate and accept mobile robots in human-centered
            spaces, prioritizing social navigation is essential. This enhances
            efficiency and promotes a socially intuitive interaction,
            considering norms and preferences. Emphasizing the robotâ€™s ability
            to navigate considerately fosters a positive user experience,
            encouraging widespread acceptance and trust in daily use. 

            Our social navigation planner is based on the foundation of Model
            Predictive Control (MPC). This choice of utilizing MPC as the
            underlying framework for our social navigation system empowers the
            robot with the capability to dynamically plan and optimize its
            movements, taking into account not only the environmental
            constraints but also the intricacies of social interactions. By
            leveraging the predictive capabilities of MPC, the planner exhibits
            responsive motions accounting for the predicted future behavior of
            the surrounding people. We specifically build on the MPC formulation
            for navigation among dynamic obstacles and humans. Furthermore, we
            perform free-space composition based on the lidar data to derive
            linear constraints for static collision avoidance. The cost function
            of the MPC can then be adapted to represent the desired social
            behavior.
          </p>
          <video id="teaser" autoplay muted loop playsinline controls height="100%">
            <source src="./assets/moving_among_humans.mp4"
                    type="video/mp4">
          </video>
          <h3 class="title is-4">Interactive Navigation</h3>
          <p>
            In the context of human-centered environments, successful navigation
            often demands the ability to interact with specific obstacles. e.g.
            a laundry basket which blocks the robot's path. This concept is
            often termed as interactive navigation. Unlike mere collision
            avoidance, interactive navigation entails a more nuanced approach,
            allowing the robot to engage with obstacles strategically, perhaps
            by repositioning, to achieve its navigational objectives effectively
            in settings. 

            The interactive skill is developed based on the nonprehensile
            manipulation capability of the mobile base, with the onboard arm
            serving as the "eyes" for tracking and locating undesired obstacles.
            Nonprehensile manipulation, characterized by not requiring precise
            grasping of objects, allows the robot to manipulate objects
            irrespective of their shape, size, or mass. Specifically, we employ
            the mobile base to push the object out of its path. Through a
            thorough analysis of contact conditions during pushing, we have
            devised a stable pushing approach. To
            enhance the flexibility of the pushing process, we leverage the
            physics simulator, Isaac Gym, and employ the sampling-based control
            method, Model Predictive Path Integral (MPPI), for motion planning
            during pushing maneuvers. This combination of capabilities enables
            the robot to navigate dynamically through its environment by
            intelligently interacting with obstacles and adapting its movements
            accordingly.
          </p>
          <h3 class="title is-4">Safe Manipulation</h3>
          <p>
            Our approach to trajectory generation is based on optimization
            fabrics. This geometric approach for trajectory
            generation encodes different behaviors, such as collision avoidance
            or joint-limit avoidance into differential equations of second
            order. Using operator from differential geometry, namely pull-back
            and push-forward, it allows to combine behaviors from different
            task-manifold into one smooth policy that converges to the goal
            state.

            Our recent adaptation to dynamic environments
            allows to deploy this approach to human-shared environments.
            Optimization fabrics offer a versatile framework for trajectory
            generation in changing environments, because it is highly reactive
            and safe. Despite its advantages, optimization
            fabrics suffer from the same problem as most other trajectory
            generation methods, such as sampling-based planners: it is
            incredibly hard to program the logic for grasps of products.
            Specifically, grasp must often be hand-composed of pre-grasp, grasp
            and post-grasp poses. We address this shortcoming, by relying on
            human reasoning and understanding of the scene and the product to be
            grasped at hand. Following our philosophy, the human operator can
            actively teach the manipulator to grasp a certain product (or a
            class of products) by dragging the robot through the workspace. This
            approach, often referred to as learning-from-demonstration, is the
            key for successful grasping in our approach and can  seamlessly be
            integrated with optimization fabrics.
            </p>

            <video id="teaser" autoplay muted loop playsinline controls height="100%">
              <source src="./assets/teaching_trajectory.mp4"
                      type="video/mp4">
            </video>

            <p>
            To provide even more safety in human-shared environments, we use a
            compliant low-level controller for tracking the desired velocity
            produced by optimization fabrics. Our low-level controller is a
            simple PID controller in velocity space that can be adapted online
            if a weight is attached to the end-effector. This choice is well in
            line with our philosophy of favoring simple solutions of evolved
            methods if possible.
            </p>
            <video id="teaser" autoplay muted loop playsinline controls height="100%">
              <source src="./assets/compliant_fabrics.mp4"
                      type="video/mp4">
            </video>
            <h3 class="title is-4">Adaptive Task Assignment</h3>
            <p>
              The high-level decision making in our robot is also based on novel
              PhD research. The goal was to create flexible behavior without
              having to hard-code all of the contingency plans for failed atomic
              actions. For example, when moving to grasp a supermarket product,
              the action could fail because the camera might lose sight of the
              product, because someone moves the product, or because someone
              manually stops the compliant arm from moving forward. 

              A regular approach to program robots to handle these contingencies
              is to create a rich Behavior Tree (BT) containing all fallback
              behaviors. Our approach is also based on BTs, but we introduce a
              novel type of leaf node to specify the desired \textit{state} to
              be achieved rather than an \textit{action} to execute. For
              example, the BT describes that the robot should be "holding an
              object" but does not specify the actions to achieve this state,
              because these change at runtime. These actions are determined at
              runtime, as explained next. 

              The resulting BT from our approach is simple to program and it
              relies on online planning through the (also novel) application of
              Active Inference. Based on neuroscience, Active Inference is a
              Bayesian inference approach that we use to essentially
              continuously calculate which of the viable atomic actions has the
              highest probability of bringing the robot closer to the desired
              states. This results in continual online planning and hierarchical
              deliberation. By doing so, an agent can follow a predefined
              offline plan while still keeping the ability to locally adapt and
              take autonomous decisions at runtime, respecting safety
              constraints.

              We have used our OPL robot to validate the hybrid Active Inference
              / Behavior Tree approach. The results showed improved runtime
              adaptability with a fraction of the hand-coded nodes compared to
              classical BTs.
            </p>

              <video id="teaser" autoplay muted loop playsinline controls height="100%">
                <source src="./assets/adaptive_task_planning.mp4"
                        type="video/mp4">
              </video>
            <h3 class="title is-4">Object Detection</h3>
            <p>
              Central to our success is an advanced computer vision pipeline
              that employs deep learning models for product and person
              detection. The product detection camera, strategically located at
              the end effector, enables the robot to efficiently identify and
              interact with grocery items on store shelves. Additionally our
              attachable perception tower at the rear of the robot, with it's 5
              Realsense depth cameras, enables us to detect the full poses of
              people surrounding the robot, using Yolo based keypoint detection.
              Notably, our research in few-shot learning allows us to seamlessly
              integrate new product classes with as few as five images, ensuring
              adaptability and scalability.
            </p>
            <video id="teaser" autoplay muted loop playsinline controls height="100%">
              <source src="./assets/adaptive_retriev.mp4"
                      type="video/mp4">
            </video>
        </div>
      </div>
    </div>
    <!--/ Methods. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!--Robothon2023. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 id="robothon" class="title is-3">Robothon 2023, Platonics</h2>
        <div class="content has-text-justified">
          <p>
            Chadi Salmi and Max Spahn have previously participated in the ERF
            Hackathon 2022 and the Robothon 2023 under the name of platonics.
            Same ideas, such as teaching trajectories for manipulation skills
            are taken from that experienced. See
            <a href="https://platonics-delft.github.io">Platonics Delft</a> for
            detailed information.
          </p>
        </div>
      </div>
    </div>
    <!--/ Robothon2023. -->
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!--Publications -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 id="publications" class="title is-3">Publications</h2>
        <div class="content has-text-justified">
          <p>
            This is a non-exhaustive lists of publications by the team members
            that are leveraged for the success of <b>HuMMUs</b>.
          </p>
          <p>
          <ul>
            <li><a href="assets/dynamic_fabrics.pdf">Dynamic Optimization Fabrics
                For Trajectory Generation, M. Spahn et al., IEEE T-RO, 2023</a></li>
            <li><a href="assets/active_inference.pdf">Active Inference and Behavior Trees for
Reactive Action Planning and Execution in Robotics, C. Pezzato et al., IEEE
T-RO, 2022</a></li>
            <li><a href="assets/active_inference_review.pdf">Active Inference in Robotics and Artificial Agents:
Survey and Challenges, P. Lanillos et al., 2021</a></li>
            <li><a href="assets/autotuning.pdf">Autotuning Symbolic Optimization
                Fabrics for Trajectory Generation, M. Spahn et al., IEEE ICRA, 2023</a></li>
            <li><a href="assets/improving_pedestrian_predections.pdf">Improving Pedestrian Prediction Models with
Self-Supervised Continual Learning, L. Knoedler, C. Salmi et al., IEEE RAL, 2022</a></li>
            <li><a href="assets/learning_guidance.pdf">Learning a Guidance Policy from
                Humans for Social Navigation, L. Knoedler et al., 2022 </a></li>
            <li><a href="assets/pushing.pdf">Unwieldy Object Delivery with Nonholonomic Mobile Base:
A Stable Pushing Approach, Y. Tang et al., IEEE RAL, 2023</a></li>
          </ul>
          </p>
        </div>
      </div>
    </div>
    <!--/Publications. -->
</section>

<section class="section">
  <div class="container is-max-desktop">

    <!--Extras. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Extras</h2>
        <div class="content has-text-justified">
          <p>
            The additional material, such as the website's source code can be
            found in the same github organizition
            <a href="https://github.com/orgs/tud-hummus">Hummus</a>:
            <ol>
              <li><a href="https://github.com/tud-hummus/tud-hummus.github.io">Website source code</a></li>
            </ol> 
            Simulation environments and individual ros packages might also be
            located in <a href="https://github.com/orgs/tud-airlab">AIRLab
              Delft</a>, as some members are part of this funding project.
          </p>
          <p>
          </p>
        </div>
      </div>
    </div>
    <!--/ Extras. -->
</section>




</body>
</html>
